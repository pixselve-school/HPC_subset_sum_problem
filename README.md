<h1 align="center">TP HCP - Subset sum problem</h1>
<h2 align="center">Algorithme: Hill Climbing</h2>
<h4 align="center">Mael KERICHARD</h4>
<p align="center">
   <img src="https://img.shields.io/badge/-ESIR-orange" alt="ESIR">
   <img src="https://img.shields.io/badge/-C-red" alt="C">
   <img src="https://img.shields.io/badge/-HCP-blue" alt="HCP">
</p>

# L'algorithme

Le fonctionnement de base du Hill Climbing est relativement simple : √† partir d'un point initial dans l'espace de
recherche, l'algorithme explore les voisins de ce point et se d√©place vers le voisin ayant la meilleure valeur de la
fonction objectif (par exemple, le voisin le plus haut dans un probl√®me de maximisation). Ce processus est r√©p√©t√©
jusqu'√† ce qu'aucun voisin n'offre d'am√©lioration, ce qui signifie que l'algorithme a atteint un sommet local.

Cependant, Hill Climbing peut facilement se retrouver pi√©g√© dans un optimum local, surtout si l'espace de recherche est
complexe avec de nombreux sommets locaux. Pour surmonter ce probl√®me, l'algorithme de Hill Climbing avec red√©marrage
al√©atoire introduit une √©tape de ¬´ red√©marrage ¬ª. Lorsque l'algorithme atteint un sommet local, au lieu de s'arr√™ter, il
red√©marre √† partir d'un point al√©atoire dans l'espace de recherche. Ce processus de red√©marrage est r√©p√©t√© plusieurs
fois. L'id√©e est qu'en explorant l'espace de recherche √† partir de diff√©rents points de d√©part, l'algorithme a une
meilleure chance de trouver un sommet global ou du moins un sommet local plus optimal que celui trouv√© lors des
tentatives pr√©c√©dentes.

# Comparaison entre la version classique et la version parall√©lis√©e

Pour plusieurs valeurs de `n`, on ex√©cute les deux versions de l'algorithme.

![283d3abf-e41d-4b25-90a1-181373aeca69.png](.github/images/283d3abf-e41d-4b25-90a1-181373aeca69.png)

<details>
  <summary>ü§î D√©tail des donn√©es g√©n√©r√©es par le programme</summary>

| n     | Density     | Execution Time (Regular) | Solution Found (Regular) | Execution Time (OpenMP) | Solution Found (OpenMP) |
|-------|-------------|--------------------------|--------------------------|-------------------------|-------------------------|
| 1000  | 142.857143  | 0.029849 seconds         | Yes                      | 0.000230 seconds        | Yes                     |
| 2000  | 285.714286  | 0.004638 seconds         | Yes                      | 0.006701 seconds        | Yes                     |
| 3000  | 428.571429  | 0.068413 seconds         | Yes                      | 0.047541 seconds        | Yes                     |
| 4000  | 571.428571  | 0.048394 seconds         | Yes                      | 0.034839 seconds        | Yes                     |
| 5000  | 714.285714  | 0.098957 seconds         | Yes                      | 0.006045 seconds        | Yes                     |
| 6000  | 857.142857  | 0.504400 seconds         | Yes                      | 0.003605 seconds        | Yes                     |
| 7000  | 1000.000000 | 0.256121 seconds         | Yes                      | 0.012735 seconds        | Yes                     |
| 8000  | 1142.857143 | 0.127218 seconds         | Yes                      | 0.028095 seconds        | Yes                     |
| 9000  | 1285.714286 | 0.919623 seconds         | Yes                      | 0.012758 seconds        | Yes                     |
| 10000 | 1428.571429 | 0.034950 seconds         | Yes                      | 0.339343 seconds        | Yes                     |

</details>

En utilisant les donn√©es fournies, la comparaison r√©v√®le des insights quantitatifs significatifs. Par
exemple, pour `n = 1000`, le temps d'ex√©cution avec la m√©thode r√©guli√®re est de `0.029849` secondes, alors qu'avec
OpenMP, il est r√©duit √† seulement 0.000230 secondes, montrant une am√©lioration remarquable de plus de 99%. Cette
tendance se maintient avec des valeurs de `n` plus √©lev√©es; par exemple, √† `n = 6000`, le temps d'ex√©cution
r√©gulier est de `0.504400` secondes contre `0.003605` secondes avec OpenMP, indiquant √† nouveau une efficacit√© accrue
avec
OpenMP.

Cependant, il est int√©ressant de noter que cette tendance n'est pas constante pour toutes les valeurs de `n`.
√Ä `n = 10000`, le temps d'ex√©cution r√©gulier est de `0.034950` secondes, tandis que pour OpenMP, il augmente
√† `0.339343`
secondes. Cette observation sugg√®re que, bien que OpenMP soit g√©n√©ralement plus efficace, il peut y avoir des cas
sp√©cifiques o√π la m√©thode r√©guli√®re peut surpasser le parall√©lisme, possiblement en raison de la surcharge li√©e √† la
gestion des threads dans OpenMP.

Ces chiffres illustrent clairement que, bien que l'approche OpenMP offre des avantages significatifs en termes de temps
d'ex√©cution dans la plupart des cas, l'efficacit√© de chaque m√©thode peut varier en fonction de la taille sp√©cifique du
probl√®me et de la complexit√© de l'ensemble de donn√©es trait√©.

## Comparaison en fixant n=500 et en variant la densit√©

![Comparaison en fixant n=500 et en variant la densit√©](.github/images/1ef5947d-cb53-40dc-a87c-7d22ff799f18.png)

Ce graphique illustre une comparaison int√©ressante entre les temps d'ex√©cution pour deux m√©thodes de traitement, Regular et OpenMP, en fonction de la densit√©. On observe que, globalement, la m√©thode OpenMP montre des temps d'ex√©cution plus courts que la m√©thode Regular, ce qui sugg√®re une meilleure efficacit√©. Cette tendance est particuli√®rement √©vidente aux densit√©s plus √©lev√©es. Il est important de noter que les diff√©rences de performance sont plus marqu√©es √† des densit√©s plus faibles. Cela indique que l'optimisation apport√©e par OpenMP est plus efficace lorsque le syst√®me g√®re des t√¢ches de moindre densit√©.